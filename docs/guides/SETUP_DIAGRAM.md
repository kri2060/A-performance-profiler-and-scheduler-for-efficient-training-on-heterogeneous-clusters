# Visual Setup Guide

Quick visual reference for setting up your heterogeneous cluster.

---

## ğŸ¯ Overview: What You're Building

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   YOUR TRAINING CLUSTER                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Master     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Worker 1   â”‚                 â”‚
â”‚  â”‚   RANK=0     â”‚         â”‚   RANK=1     â”‚                 â”‚
â”‚  â”‚ GPU/CPU      â”‚         â”‚   GPU/CPU    â”‚                 â”‚
â”‚  â”‚192.168.1.100 â”‚         â”‚192.168.1.101 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                                                    â”‚
â”‚         â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Worker 2   â”‚                 â”‚
â”‚         â”‚                 â”‚   RANK=2     â”‚                 â”‚
â”‚         â”‚                 â”‚   GPU/CPU    â”‚                 â”‚
â”‚         â”‚                 â”‚192.168.1.102 â”‚                 â”‚
â”‚         â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                                                    â”‚
â”‚         â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Worker 3   â”‚                 â”‚
â”‚                           â”‚   RANK=3     â”‚                 â”‚
â”‚                           â”‚   GPU/CPU    â”‚                 â”‚
â”‚                           â”‚192.168.1.103 â”‚                 â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                              â”‚
â”‚  Communication: Port 29500 (TCP)                            â”‚
â”‚  Backend: Gloo (CPU/mixed) or NCCL (all-GPU)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Configuration Matrix

| Machine | Role | IP | RANK | GPU | Batch Size |
|---------|------|-------|------|-----|------------|
| Machine 1 | Master | 192.168.1.100 | 0 | RTX 3070 | 64 |
| Machine 2 | Worker | 192.168.1.101 | 1 | GTX 1660 | 64 |
| Machine 3 | Worker | 192.168.1.102 | 2 | CPU only | 32 |
| Machine 4 | Worker | 192.168.1.103 | 3 | CPU only | 32 |

**WORLD_SIZE = 4** (all machines)

---

## ğŸ”„ Setup Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SETUP WORKFLOW                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Prepare  â”‚
â”‚   All       â”‚  â†’ Install Docker on all machines
â”‚  Machines   â”‚  â†’ Check network connectivity
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â†’ Open firewall (port 29500)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Choose   â”‚  â†’ Option A: Docker Hub (fastest)
â”‚ Deployment  â”‚  â†’ Option B: Build locally
â”‚   Method    â”‚  â†’ Option C: Save/load image
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Setup    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Master    â”‚â”€>â”‚ export WORLD_SIZE=4             â”‚
â”‚  (RANK=0)   â”‚  â”‚ ./docker_run_master_adaptive.sh â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚  Master outputs: "Master IP: 192.168.1.100"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Setup    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 1   â”‚â”€>â”‚ export MASTER_ADDR=192.168.1.100â”‚
â”‚  (RANK=1)   â”‚  â”‚ export RANK=1                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚ export WORLD_SIZE=4             â”‚
       â”‚         â”‚ ./docker_run_worker_adaptive.sh â”‚
       â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Setup    â”‚  Same as Worker 1, but RANK=2
â”‚  Worker 2   â”‚
â”‚  (RANK=2)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Setup    â”‚  Same as Worker 1, but RANK=3
â”‚  Worker 3   â”‚
â”‚  (RANK=3)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Training â”‚  Starts automatically when all
â”‚   Starts!   â”‚  workers connect to master
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Network Topology

```
         Internet/LAN
              â”‚
        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
        â”‚  Router   â”‚
        â”‚ (Gateway) â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚         â”‚         â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”
â”‚Master â”‚ â”‚Work 1â”‚ â”‚Work 2â”‚ â”‚Work 3â”‚
â”‚  :100 â”‚ â”‚  :101â”‚ â”‚  :102â”‚ â”‚  :103â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜

Network: 192.168.1.0/24
Master Port: 29500 (must be open)
```

**Firewall Rules:**
```
Master: Allow incoming on port 29500
Workers: Allow outgoing to master:29500
```

---

## ğŸ³ Docker Container Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER CONTAINER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  PyTorch Distributed Process Group                 â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚  Training   â”‚  â”‚  Profiler    â”‚                â”‚ â”‚
â”‚  â”‚  â”‚  Loop       â”‚  â”‚  (GPU/CPU)   â”‚                â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚ Load        â”‚  â”‚  Metrics     â”‚                â”‚ â”‚
â”‚  â”‚  â”‚ Balancer    â”‚  â”‚  Collector   â”‚                â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Volumes:                                               â”‚
â”‚  â€¢ /workspace â†’ Project code                           â”‚
â”‚  â€¢ /experiments â†’ Results & checkpoints                â”‚
â”‚                                                          â”‚
â”‚  Environment:                                            â”‚
â”‚  â€¢ MASTER_ADDR, RANK, WORLD_SIZE                       â”‚
â”‚                                                          â”‚
â”‚  Network:                                                â”‚
â”‚  â€¢ --network host (Linux) or port mapping (Windows)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Environment Variables Flow

```
Master Node (RANK=0):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ export WORLD_SIZE=4    â”‚ â† Total machines
â”‚ (RANK=0 automatic)     â”‚ â† Master is always 0
â”‚ (MASTER_ADDR auto)     â”‚ â† Detected automatically
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Shares IP: 192.168.1.100
           â–¼
Worker Nodes (RANK=1,2,3):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ export MASTER_ADDR=... â”‚ â† From master
â”‚ export RANK=1          â”‚ â† Unique per worker
â”‚ export WORLD_SIZE=4    â”‚ â† Same as master
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Rules:**
1. **WORLD_SIZE** must be SAME on all machines
2. **RANK** must be UNIQUE (0, 1, 2, 3...)
3. **MASTER_ADDR** must be reachable from all workers

---

## ğŸ“Š Training Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   TRAINING ITERATION                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Forward Pass (Each Rank Independent)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Rank 0  â”‚   â”‚Rank 1  â”‚   â”‚Rank 2  â”‚   â”‚Rank 3  â”‚
   â”‚Batch 64â”‚   â”‚Batch 64â”‚   â”‚Batch 32â”‚   â”‚Batch 32â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚            â”‚            â”‚            â”‚
       â–¼            â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Model  â”‚   â”‚ Model  â”‚   â”‚ Model  â”‚   â”‚ Model  â”‚
   â”‚Forward â”‚   â”‚Forward â”‚   â”‚Forward â”‚   â”‚Forward â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚            â”‚            â”‚            â”‚
       â–¼            â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Loss   â”‚   â”‚ Loss   â”‚   â”‚ Loss   â”‚   â”‚ Loss   â”‚
   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚            â”‚            â”‚            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
2. Gradient Synchronization (AllReduce)
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Average        â”‚
           â”‚  Gradients      â”‚
           â”‚  across ranks   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼            â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Update  â”‚   â”‚Update  â”‚   â”‚Update  â”‚   â”‚Update  â”‚
   â”‚Weights â”‚   â”‚Weights â”‚   â”‚Weights â”‚   â”‚Weights â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. Load Balancer (Optional)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Measure: iteration time/rank    â”‚
   â”‚ Adjust: batch sizes dynamically â”‚
   â”‚ Goal: minimize stragglers       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Hardware Detection Flow

```
Container Starts
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check nvidia-smiâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ GPU?    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                          â”‚
    â–¼ YES                      â–¼ NO
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚GPU Mode â”‚              â”‚CPU Mode  â”‚
â”‚         â”‚              â”‚          â”‚
â”‚â€¢ CUDA   â”‚              â”‚â€¢ CPU     â”‚
â”‚â€¢ Batch64â”‚              â”‚â€¢ Batch32 â”‚
â”‚â€¢ NCCL/  â”‚              â”‚â€¢ Gloo    â”‚
â”‚  Gloo   â”‚              â”‚          â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Start Training â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Automatic Features:**
- âœ… GPU/CPU detection
- âœ… Batch size adjustment
- âœ… Backend selection
- âœ… Memory optimization

---

## ğŸš¦ Launch Sequence Timeline

```
Time    Master                  Worker 1              Worker 2              Worker 3
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0s      Start master
        Build/pull image

5s      Master ready
        Listening on :29500
        "Waiting 60s..."

10s                             Start worker 1
                                Pull image

15s                             Connect to master     Start worker 2
                                                      Pull image

20s                             Connected âœ“           Connect to master    Start worker 3
                                                                           Pull image

25s                                                   Connected âœ“          Connect to master

30s                                                                        Connected âœ“

35s     All workers connected!
        Initialize training

40s     Start Epoch 1          Start Epoch 1         Start Epoch 1        Start Epoch 1

45s     Training...            Training...           Training...          Training...
        â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“            â–“â–“â–“â–“â–“â–“â–“â–“              â–“â–“â–“                  â–“â–“â–“
        (fast GPU)             (medium GPU)          (slow CPU)           (slow CPU)
```

**Key Points:**
- Master starts first (waits 60s)
- Workers connect within 60s window
- Training begins when all connect
- Different speeds are normal (heterogeneous!)

---

## ğŸ“ˆ Performance Expectations

```
Single GPU (baseline):         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  100% (256 samples/s)

2 GPUs (homogeneous):          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  200% (512 samples/s)
                               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

2 GPUs (heterogeneous):        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  180% (460 samples/s)
RTX 3070                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (faster)
GTX 1660                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          (slower)

2 GPUs + 2 CPUs (mixed):       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  220% (563 samples/s)
RTX 3070                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
GTX 1660                       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
CPU 1                          â–ˆâ–ˆâ–ˆ
CPU 2                          â–ˆâ–ˆ

With Load Balancing:           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  240% (614 samples/s)
RTX 3070 (optimized)           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
GTX 1660 (optimized)           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
CPU 1 (optimized)              â–ˆâ–ˆâ–ˆâ–ˆ
CPU 2 (optimized)              â–ˆâ–ˆâ–ˆâ–ˆ
```

**Benefits:**
- Utilize all available hardware
- 20-40% speedup with load balancing
- Scale linearly with more machines

---

## ğŸ” Verification Checklist

```
Before Starting:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â˜ Docker installed on all machines         â”‚
â”‚ â˜ Machines can ping each other             â”‚
â”‚ â˜ Port 29500 open on master                â”‚
â”‚ â˜ Same WORLD_SIZE on all machines          â”‚
â”‚ â˜ Unique RANK for each worker              â”‚
â”‚ â˜ Master IP noted and shared               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After Starting:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â˜ Master container running                  â”‚
â”‚ â˜ All worker containers running             â”‚
â”‚ â˜ No connection errors in logs              â”‚
â”‚ â˜ Training started (check logs)             â”‚
â”‚ â˜ Loss decreasing each epoch                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Quick Command Reference

### Master:
```bash
export WORLD_SIZE=4
./scripts/docker_run_master_adaptive.sh
```

### Worker (Linux/Mac):
```bash
export MASTER_ADDR=192.168.1.100
export RANK=1  # Unique!
export WORLD_SIZE=4
./scripts/docker_run_worker_adaptive.sh
```

### Worker (Windows):
```cmd
set MASTER_ADDR=192.168.1.100
set RANK=1
set WORLD_SIZE=4
scripts\docker_run_worker_adaptive.bat
```

### Monitor:
```bash
docker logs -f hetero-master
docker ps
./scripts/docker_run_dashboard.sh
```

---

## ğŸ“ Next Steps

1. âœ… Understand the architecture (this document)
2. ğŸ“‹ Complete prerequisites ([SETUP_CHECKLIST.md](SETUP_CHECKLIST.md))
3. ğŸš€ Follow quick start ([QUICK_START_MULTINODE.md](QUICK_START_MULTINODE.md))
4. ğŸ“Š Launch training ([LAUNCH_GUIDE.md](LAUNCH_GUIDE.md))
5. ğŸ‰ Enjoy distributed training!

---

**Ready to build your cluster? Start here:** [QUICK_START_MULTINODE.md](QUICK_START_MULTINODE.md) ğŸš€
